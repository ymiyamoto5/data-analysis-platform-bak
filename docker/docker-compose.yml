version: '3'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.14.0
    hostname: doc-elastic
    environment:
      - discovery.type=single-node
      - cluster.name=docker-cluster
      - network.host=0.0.0.0
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=P@ssw0rd
      - bootstrap.memory_lock=true
      - 'ES_JAVA_OPTS=-Xms4096m -Xmx4096m'
    ulimits:
      memlock:
        soft: -1
        hard: -1
    restart: always
    ports:
      - '9200:9200/tcp'
    network_mode: 'host'
    volumes:
      - /mnt/datadrive/data:/usr/share/elasticsearch/data
  kibana:
    image: docker.elastic.co/kibana/kibana:7.14.0
    environment:
      SERVER_NAME: 'kibana'
      ELASTICSEARCH_HOSTS: 'http://0.0.0.0:9200'
      ELASTICSEARCH_REQUESTTIMEOUT: '60000'
      ELASTICSEARCH_USERNAME: 'elastic'
      ELASTICSEARCH_PASSWORD: 'P@ssw0rd'
      I18N_LOCALE: 'ja-JP'
    restart: always
    ports:
      - '5601:5601/tcp'
    network_mode: 'host'
    depends_on:
      - elasticsearch
  notebook:
    image: build_jupyter/base-notebook
    build:
      context: ~/data-analysis-platform
      dockerfile: ./docker/jupyter.dockerfile
    env_file: ~/data-analysis-platform/.env
    restart: always
    ports:
      - '8888:8888/tcp'
    working_dir: '/home/jovyan/work'
    volumes:
      - ~/data-analysis-platform/notebooks:/home/jovyan/work
      - ~/data-analysis-platform/backend:/home/jovyan/backend
      - /mnt/datadrive/data:/mnt/datadrive/data
    command: start-notebook.sh --NotebookApp.token=''
    network_mode: 'host'
  webap:
    build:
      context: ~/data-analysis-platform
      dockerfile: ./docker/webap.dockerfile
    environment:
      MODULE_NAME: 'backend.app.main'
    env_file: ~/data-analysis-platform/.env
    restart: always
    ports:
      - '80:80/tcp'
    volumes:
      - /mnt/datadrive:/mnt/datadrive
      - /run:/run
      - ~/data-analysis-platform/backend:/app/backend
    network_mode: 'host'
    depends_on:
      - elasticsearch
  metricbeat:
    image: build_docker.elastic.co/beats/metricbeat:7.14.0
    build:
      context: ~/data-analysis-platform
      dockerfile: ./docker/metricbeat.dockerfile
    user: root
    env_file: ~/data-analysis-platform/.env
    environment:
      - ELASTICSEARCH_HOST=localhost:9200
      - KIBANA_HOST=localhost:5601
      - NO_PROXY=localhost
    restart: always
    volumes:
      - /proc:/hostfs/proc:ro
      - /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro
      - /:/hostfs:ro
      - /var/run/docker.sock:/var/run/docker.sock
      # - ~/data-analysis-platform/docker/metricbeat.docker.yml:/usr/share/metricbeat/metricbeat.yml:ro
    command: -system.hostfs=/hostfs
    network_mode: 'host'
    depends_on:
      - elasticsearch
  mlflow:
    build:
      context: .
      dockerfile: ./mlflow.dockerfile
    volumes:
      - mlflow:/mlflow
    ports:
      - 5000:5000
    depends_on:
      - minio
    environment:
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: minio-access-key
      AWS_SECRET_ACCESS_KEY: minio-secret-key
    command: mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root s3://default/ --host 0.0.0.0 --port 5000
    restart: always
    networks:
      - mlflow_network
  minio:
    image: minio/minio
    ports:
      - 9000:9000
      - 9001:9001
    restart: always
    volumes:
      - minio1:/export
    environment:
      MINIO_ROOT_USER: minio-access-key
      MINIO_ROOT_PASSWORD: minio-secret-key
    command: server /export --console-address :9001
    networks:
      - mlflow_network

  defaultbucket:
    image: minio/mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc alias set minio http://minio:9000 minio-access-key minio-secret-key) do echo 'try to create buckets...' && sleep 1; done;
      /usr/bin/mc mb minio/default;
      /usr/bin/mc policy set public minio/default;
      exit 0;
      "
    networks:
      - mlflow_network
  rabbitmq:
    image: rabbitmq:3-management
    environment:
      - RABBITMQ_DEFAULT_USER=guest
      - RABBITMQ_DEFAULT_PASS=guest
    ports:
      - "4369:4369"
      - "5672:5672"
      - "25672:25672"
      - "15672:15672"
  redis:
    image: redis:latest
    ports:
      - "6379:6379"
  worker:
    build:
      context: ~/data-analysis-platform
      dockerfile: docker/celery.dockerfile
    volumes:
      - ~/data-analysis-platform/backend:/backend
      - /mnt/datadrive:/mnt/datadrive  
    env_file: ~/data-analysis-platform/.env
    network_mode: 'host'    
    # environment:
    #   - CELERY_BROKER_URL=pyamqp://guest:guest@rabbitmq:5672
    #   - CELERY_RESULT_BACKEND=redis://redis:6379/0
    command: celery -A backend.app.worker worker -l info -c 4
    depends_on:
      - webap
      - rabbitmq
      - redis
  flower:  
    image: mher/flower
    environment:
      - no_proxy=rabbitmq
      - CELERY_BROKER_URL=pyamqp://guest:guest@rabbitmq:5672
      - FLOWER_PORT=5555
    ports:  
      - 5555:5555
    depends_on:
      - rabbitmq
      - worker

networks:
  mlflow_network:
    driver: bridge

volumes:
  mlflow:
  minio1:
