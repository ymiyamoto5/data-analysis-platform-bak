{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import eland as ed\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../src/'))\n",
    "from data_reader.data_reader import DataReader\n",
    "from elastic_manager.elastic_manager import ElasticManager\n",
    "sys.path.append(os.path.join(os.getcwd(), '../src/analyze/'))\n",
    "from analyze.h_one_extract_features import *\n",
    "from analyze.analyze import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"20210701180000\"\n",
    "shots_data_index = \"shots-\" + target + \"-data\"\n",
    "shots_meta_index = \"shots-\" + target + \"-meta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 s, sys: 3.45 s, total: 25.4 s\n",
      "Wall time: 50.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dr = DataReader()\n",
    "shots_df = dr.multi_process_read_all(shots_data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3150000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shots_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>shot_number</th>\n",
       "      <th>num_of_samples_in_cut_out</th>\n",
       "      <th>spm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-01T09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-01T09:00:03</td>\n",
       "      <td>2</td>\n",
       "      <td>3000</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-01T09:00:06</td>\n",
       "      <td>3</td>\n",
       "      <td>3000</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-01T09:00:09</td>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-01T09:00:12</td>\n",
       "      <td>5</td>\n",
       "      <td>3000</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  shot_number  num_of_samples_in_cut_out   spm\n",
       "0  2021-07-01T09:00:00            1                       3000  20.0\n",
       "1  2021-07-01T09:00:03            2                       3000  20.0\n",
       "2  2021-07-01T09:00:06            3                       3000  20.0\n",
       "3  2021-07-01T09:00:09            4                       3000  20.0\n",
       "4  2021-07-01T09:00:12            5                       3000  20.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ショットメタデータを確認\n",
    "shots_meta_df = dr.read_shots_meta(shots_meta_index)\n",
    "shots_meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ショット数：1050\n"
     ]
    }
   ],
   "source": [
    "print(f\"ショット数：{len(shots_meta_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50サンプルごとに間引いたcontour図作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "mask = np.array(\n",
    "    [\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "    ]\n",
    ")\n",
    "mask = mask / 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude_shots=(983, 1227, 1228, 1229, 1369, 1381, 2894)\n",
    "exclude_shots=()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 荷重開始から破断までの間を対象とし、コンタ―図を作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.71s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "contour_index = \"shots-\" + target + \"-contour\"\n",
    "ElasticManager.delete_index(index=contour_index)\n",
    "ElasticManager.create_index(index=contour_index)\n",
    "\n",
    "dr = DataReader()\n",
    "start_index = \"shots-\" + target + \"-start-point\"\n",
    "start_df = dr.read_all(start_index)\n",
    "break_index = \"shots-\" + target + \"-break-point\"\n",
    "break_df = dr.read_all(break_index)\n",
    "\n",
    "for shot_number in tqdm(range(1, 11)): # 全ショットは重いので一部のショットのみ\n",
    "    if shot_number in exclude_shots:\n",
    "        continue\n",
    "    \n",
    "    shot_df = shots_df[shots_df.shot_number == shot_number].reset_index()\n",
    "    # コンタ―図の対象範囲を荷重開始点および破断点から設定\n",
    "    start_point = int(start_df[(start_df.shot_number == shot_number) & (start_df.load == \"load01\")].sequential_number_by_shot)\n",
    "    # 破断ch (load01/02のセット or load03/04のセット)\n",
    "    break_ch = \"load01\" if break_df[break_df.shot_number == shot_number].reset_index().break_channels[0][0] == \"load01\" else \"load03\"\n",
    "    end_point = int(break_df[(break_df.shot_number == shot_number) & (break_df.load == break_ch)].sequential_number_by_shot)\n",
    "    # コンター図にする間隔。暫定で80枚の図を作成。\n",
    "    interval = (end_point - start_point) // 80\n",
    "    # print(start_point, end_point, interval, break_ch)\n",
    "    \n",
    "    h_contor_array = []\n",
    "    timestamp_by_fig = [] # 1枚の図毎のタイムスタンプ\n",
    "\n",
    "    # 80枚のコンタ―図を生成\n",
    "    for i in range(0, 80):\n",
    "        timestamp_by_fig.append(shot_df.timestamp.loc[0])\n",
    "\n",
    "        z = np.zeros((64, 64), dtype=\"float64\")\n",
    "        t = start_point + i * interval\n",
    "        z[20, 20] = shot_df.load01[t]\n",
    "        z[20, 40] = shot_df.load02[t]\n",
    "        z[40, 20] = shot_df.load03[t]\n",
    "        z[40, 40] = shot_df.load04[t]\n",
    "\n",
    "        _a = scipy.signal.correlate2d(z, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        h_contor_array.append(_a)\n",
    "\n",
    "    h_contor_array = np.array(h_contor_array)\n",
    "    h_contor_array_reshaped = h_contor_array.reshape(80,-1)\n",
    "    \n",
    "    # create doc\n",
    "    for i in range(0, 80):\n",
    "        query = {\n",
    "            \"shot_number\": shot_number,\n",
    "            \"number\": i+1,\n",
    "            \"width\": 64,\n",
    "            \"height\": 64,\n",
    "            \"values\": h_contor_array_reshaped[i]\n",
    "        }\n",
    "        doc_id = 80*(shot_number-1) + i\n",
    "        ElasticManager.create_doc(index=contour_index, doc_id=doc_id, query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴点ごとのコンタ―図"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 荷重開始点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1050/1050 [02:43<00:00,  6.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "start_contour_index = \"shots-\" + target + \"-start-contour\"\n",
    "ElasticManager.delete_index(index=start_contour_index)\n",
    "ElasticManager.create_index(index=start_contour_index)\n",
    "\n",
    "# 荷重開始点\n",
    "dr = DataReader()\n",
    "start_index = \"shots-\" + target + \"-start-point\"\n",
    "start_df = dr.read_all(start_index)\n",
    "\n",
    "for shot_number in tqdm(range(1, len(shots_meta_df)+1)):\n",
    "    if shot_number in exclude_shots:\n",
    "        continue\n",
    "        \n",
    "    shot_df = shots_df[shots_df.shot_number == shot_number].reset_index(drop=True)        \n",
    "    # print(shot_df.head(3))\n",
    "    start_in_shot_df = start_df[start_df.shot_number == shot_number].reset_index(drop=True)\n",
    "#     from IPython.core.debugger import Pdb; Pdb().set_trace()    \n",
    "    \n",
    "    h_contor_array = []\n",
    "    timestamp_by_ch = [] # ch毎のタイムスタンプ\n",
    "\n",
    "    # ch毎に1枚、計4枚のコンタ―図を作成\n",
    "    for target_ch in [\"load01\", \"load02\", \"load03\", \"load04\"]:\n",
    "        df = start_in_shot_df[start_in_shot_df.load == target_ch].reset_index(drop=True)\n",
    "        # 開始点のインデックス番号\n",
    "        start_idx = int(df.sequential_number)\n",
    "        # 開始点のインデックスにおける各chの荷重値\n",
    "        channels_df = shot_df[shot_df.sequential_number == start_idx].reset_index(drop=True)\n",
    "        load01 = float(channels_df.load01)\n",
    "        load02 = float(channels_df.load02)\n",
    "        load03 = float(channels_df.load03)\n",
    "        load04 = float(channels_df.load04)    \n",
    "\n",
    "        timestamp_by_ch.append(channels_df.timestamp.loc[0])\n",
    "        \n",
    "        z = np.zeros((64, 64), dtype=\"float64\")\n",
    "        z[20, 20] = load01\n",
    "        z[20, 40] = load02\n",
    "        z[40, 20] = load03\n",
    "        z[40, 40] = load04\n",
    "\n",
    "        _a = scipy.signal.correlate2d(z, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        h_contor_array.append(_a)\n",
    "\n",
    "    h_contor_array = np.array(h_contor_array) # (1, 64, 64)\n",
    "    h_contor_array_reshaped = h_contor_array.reshape(4,-1) # (4, 64*64=4096)\n",
    "    # from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "    \n",
    "    # create doc\n",
    "    for i, load in enumerate([\"load01\", \"load02\", \"load03\", \"load04\"]):\n",
    "        query = {\n",
    "            \"timestamp\": timestamp_by_ch[i],\n",
    "            \"shot_number\": shot_number,\n",
    "            \"load\": load,\n",
    "            \"width\": 64,\n",
    "            \"height\": 64,\n",
    "            \"values\": h_contor_array_reshaped[i]\n",
    "        }\n",
    "        doc_id = 4*(shot_number-1) + i\n",
    "        ElasticManager.create_doc(index=start_contour_index, doc_id=doc_id, query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最大荷重点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "shots-20210701180000-max-contourが存在しません。\n",
      "100%|██████████| 1050/1050 [02:38<00:00,  6.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "max_contour_index = \"shots-\" + target + \"-max-contour\"\n",
    "ElasticManager.delete_index(index=max_contour_index)\n",
    "ElasticManager.create_index(index=max_contour_index)\n",
    "\n",
    "dr = DataReader()\n",
    "max_index = \"shots-\" + target + \"-max-point\"\n",
    "max_df = dr.read_all(max_index)\n",
    "\n",
    "for shot_number in tqdm(range(1, len(shots_meta_df)+1)): # 全ショットは重いので一部のショットのみ\n",
    "    if shot_number in exclude_shots:\n",
    "        continue\n",
    "        \n",
    "    shot_df = shots_df[shots_df.shot_number == shot_number].reset_index(drop=True)        \n",
    "    # print(shot_df.head(3))\n",
    "    max_in_shot_df = max_df[max_df.shot_number == shot_number].reset_index(drop=True)\n",
    "#     from IPython.core.debugger import Pdb; Pdb().set_trace()    \n",
    "    # ch毎に1枚、計4枚のコンタ―図を作成\n",
    "    \n",
    "    h_contor_array = []\n",
    "    timestamp_by_ch = [] # ch毎のタイムスタンプ\n",
    "    \n",
    "    for target_ch in [\"load01\", \"load02\", \"load03\", \"load04\"]:\n",
    "        df = max_in_shot_df[max_in_shot_df.load == target_ch].reset_index(drop=True)\n",
    "        # 最大点のインデックス番号\n",
    "        max_idx = int(df.sequential_number)\n",
    "        # 最大点のインデックスにおける各chの荷重値\n",
    "        channels_df = shot_df[shot_df.sequential_number == max_idx].reset_index(drop=True)\n",
    "        load01 = float(channels_df.load01)\n",
    "        load02 = float(channels_df.load02)\n",
    "        load03 = float(channels_df.load03)\n",
    "        load04 = float(channels_df.load04)    \n",
    "\n",
    "        timestamp_by_ch.append(channels_df.timestamp.loc[0])\n",
    "        \n",
    "        z = np.zeros((64, 64), dtype=\"float64\")\n",
    "        z[20, 20] = load01\n",
    "        z[20, 40] = load02\n",
    "        z[40, 20] = load03\n",
    "        z[40, 40] = load04\n",
    "\n",
    "        _a = scipy.signal.correlate2d(z, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        h_contor_array.append(_a)\n",
    "\n",
    "    h_contor_array = np.array(h_contor_array) # (1, 64, 64)\n",
    "    h_contor_array_reshaped = h_contor_array.reshape(4,-1) # (4, 64*64=4096)\n",
    "\n",
    "    for i, load in enumerate([\"load01\", \"load02\", \"load03\", \"load04\"]):\n",
    "        query = {\n",
    "            \"timestamp\": timestamp_by_ch[i],\n",
    "            \"shot_number\": shot_number,\n",
    "            \"load\": load,\n",
    "            \"width\": 64,\n",
    "            \"height\": 64,\n",
    "            \"values\": h_contor_array_reshaped[i]\n",
    "        }\n",
    "        doc_id = 4*(shot_number-1) + i\n",
    "        ElasticManager.create_doc(index=max_contour_index, doc_id=doc_id, query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 破断点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "shots-20210701180000-break-contourが存在しません。\n",
      "100%|██████████| 1050/1050 [02:39<00:00,  6.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "break_contour_index = \"shots-\" + target + \"-break-contour\"\n",
    "ElasticManager.delete_index(index=break_contour_index)\n",
    "ElasticManager.create_index(index=break_contour_index)\n",
    "\n",
    "dr = DataReader()\n",
    "break_index = \"shots-\" + target + \"-break-point\"\n",
    "break_df = dr.read_all(break_index)\n",
    "\n",
    "for shot_number in tqdm(range(1, len(shots_meta_df)+1)): # 全ショットは重いので一部のショットのみ\n",
    "    if shot_number in exclude_shots:\n",
    "        continue\n",
    "        \n",
    "    shot_df = shots_df[shots_df.shot_number == shot_number].reset_index(drop=True)        \n",
    "    break_in_shot_df = break_df[break_df.shot_number == shot_number].reset_index(drop=True)\n",
    "#     from IPython.core.debugger import Pdb; Pdb().set_trace()    \n",
    "    \n",
    "    h_contor_array = []\n",
    "    timestamp_by_ch = [] # ch毎のタイムスタンプ\n",
    "    \n",
    "    # ch毎に1枚、計4枚のコンタ―図を作成\n",
    "    for target_ch in [\"load01\", \"load02\", \"load03\", \"load04\"]:\n",
    "        df = break_in_shot_df[break_in_shot_df.load == target_ch].reset_index(drop=True)\n",
    "        # 破断点のインデックス番号\n",
    "        break_idx = int(df.sequential_number)\n",
    "        # 破断点のインデックスにおける各chの荷重値\n",
    "        channels_df = shot_df[shot_df.sequential_number == break_idx].reset_index(drop=True)\n",
    "        load01 = float(channels_df.load01)\n",
    "        load02 = float(channels_df.load02)\n",
    "        load03 = float(channels_df.load03)\n",
    "        load04 = float(channels_df.load04)    \n",
    "\n",
    "        timestamp_by_ch.append(channels_df.timestamp.loc[0])\n",
    "        \n",
    "        z = np.zeros((64, 64), dtype=\"float64\")\n",
    "        z[20, 20] = load01\n",
    "        z[20, 40] = load02\n",
    "        z[40, 20] = load03\n",
    "        z[40, 40] = load04\n",
    "\n",
    "        _a = scipy.signal.correlate2d(z, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        h_contor_array.append(_a)\n",
    "\n",
    "    h_contor_array = np.array(h_contor_array) # (1, 64, 64)\n",
    "    h_contor_array_reshaped = h_contor_array.reshape(4,-1) # (4, 64*64=4096)\n",
    "    # from IPython.core.debugger import Pdb; Pdb().set_trace() \n",
    "\n",
    "    # create doc\n",
    "    for i, load in enumerate([\"load01\", \"load02\", \"load03\", \"load04\"]):\n",
    "        query = {\n",
    "            \"timestamp\": timestamp_by_ch[i],\n",
    "            \"shot_number\": shot_number,\n",
    "            \"load\": load,\n",
    "            \"width\": 64,\n",
    "            \"height\": 64,\n",
    "            \"values\": h_contor_array_reshaped[i]\n",
    "        }\n",
    "        doc_id = 4*(shot_number-1) + i\n",
    "        ElasticManager.create_doc(index=break_contour_index, doc_id=doc_id, query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下テンポラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_contor_array.shape\n",
    "h_c_ = h_contor_array.reshape(80,-1)\n",
    "h_c_[0].shape\n",
    "#print(h_c_.min(), h_c_.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 80):\n",
    "    query = {\n",
    "        \"number\": i+1,\n",
    "        \"width\": 64,\n",
    "        \"height\": 64,\n",
    "        \"values\": h_c_[i]\n",
    "    }\n",
    "    ElasticManager.create_doc(index=\"contour-001\", doc_id=i, query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElasticManager.delete_index(index=\"contour-001\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
