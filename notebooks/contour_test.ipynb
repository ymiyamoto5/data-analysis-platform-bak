{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import eland as ed\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../src/'))\n",
    "from data_reader.data_reader import DataReader\n",
    "from elastic_manager.elastic_manager import ElasticManager\n",
    "sys.path.append(os.path.join(os.getcwd(), '../src/analyze/'))\n",
    "from analyze.h_one_extract_features import *\n",
    "from analyze.analyze import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"20210327141514\"\n",
    "shots_data_index = \"shots-\" + target + \"-data\"\n",
    "shots_meta_index = \"shots-\" + target + \"-meta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 7.73 s, total: 1min 52s\n",
      "Wall time: 3min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dr = DataReader()\n",
    "shots_df = dr.multi_process_read_all(shots_data_index)\n",
    "#shots_df = dr.read_shot(index=shots_data_index, shot_number=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13590838"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shots_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>shot_number</th>\n",
       "      <th>spm</th>\n",
       "      <th>num_of_samples_in_cut_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-27T05:16:25.150651</td>\n",
       "      <td>1</td>\n",
       "      <td>50.847458</td>\n",
       "      <td>109404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-27T05:16:26.333224</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-27T05:16:40.974641</td>\n",
       "      <td>3</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>9877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-27T05:16:43.071635</td>\n",
       "      <td>4</td>\n",
       "      <td>32.608696</td>\n",
       "      <td>8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-27T05:16:44.916517</td>\n",
       "      <td>5</td>\n",
       "      <td>35.928144</td>\n",
       "      <td>7798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp  shot_number        spm  \\\n",
       "0  2021-03-27T05:16:25.150651            1  50.847458   \n",
       "1  2021-03-27T05:16:26.333224            2        NaN   \n",
       "2  2021-03-27T05:16:40.974641            3  28.571429   \n",
       "3  2021-03-27T05:16:43.071635            4  32.608696   \n",
       "4  2021-03-27T05:16:44.916517            5  35.928144   \n",
       "\n",
       "   num_of_samples_in_cut_out  \n",
       "0                     109404  \n",
       "1                      16564  \n",
       "2                       9877  \n",
       "3                       8640  \n",
       "4                       7798  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ショットメタデータを確認\n",
    "shots_meta_df = dr.read_shots_meta(shots_meta_index)\n",
    "shots_meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ショット数：3264\n"
     ]
    }
   ],
   "source": [
    "print(f\"ショット数：{len(shots_meta_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50サンプルごとに間引いたcontour図作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "mask = np.array(\n",
    "    [\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1,],\n",
    "    ]\n",
    ")\n",
    "mask = mask / 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_shots=(983, 1227, 1228, 1229, 1369, 1381, 2894)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:26<00:00,  2.68s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "contour_index = \"shots-\" + target + \"-contour\"\n",
    "ElasticManager.delete_index(index=contour_index)\n",
    "ElasticManager.create_index(index=contour_index)\n",
    "\n",
    "dr = DataReader()\n",
    "start_index = \"shots-\" + target + \"-start-point\"\n",
    "start_df = dr.read_all(start_index)\n",
    "break_index = \"shots-\" + target + \"-break-point\"\n",
    "break_df = dr.read_all(break_index)\n",
    "\n",
    "for shot_number in tqdm(range(1, 11)): # 全ショットは重いので一部のショットのみ\n",
    "    if shot_number in exclude_shots:\n",
    "        continue\n",
    "    \n",
    "    shot_df = shots_df[shots_df.shot_number == shot_number].reset_index()\n",
    "    # コンタ―図の対象範囲を荷重開始点および破断点から設定\n",
    "    start_point = int(start_df[(start_df.shot_number == shot_number) & (start_df.load == \"load01\")].sequential_number_by_shot)\n",
    "    # 破断ch (load01/02のセット or load03/04のセット)\n",
    "    break_ch = \"load01\" if break_df[break_df.shot_number == shot_number].reset_index().break_channels[0][0] == \"load01\" else \"load03\"\n",
    "    end_point = int(break_df[(break_df.shot_number == shot_number) & (break_df.load == break_ch)].sequential_number_by_shot)\n",
    "    # コンター図にする間隔。暫定で80枚の図を作成。\n",
    "    interval = (end_point - start_point) // 80\n",
    "    # print(start_point, end_point, interval, break_ch)\n",
    "    \n",
    "    h_contor_array = []\n",
    "    timestamp_by_fig = [] # 1枚の図毎のタイムスタンプ\n",
    "\n",
    "    # 80枚のコンタ―図を生成\n",
    "    for i in range(0, 80):\n",
    "        timestamp_by_fig.append(shot_df.timestamp.loc[0])\n",
    "\n",
    "        z = np.zeros((64, 64), dtype=\"float64\")\n",
    "        t = start_point + i * interval\n",
    "        z[20, 20] = shot_df.load01[t]\n",
    "        z[20, 40] = shot_df.load02[t]\n",
    "        z[40, 20] = shot_df.load03[t]\n",
    "        z[40, 40] = shot_df.load04[t]\n",
    "\n",
    "        _a = scipy.signal.correlate2d(z, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        h_contor_array.append(_a)\n",
    "\n",
    "    h_contor_array = np.array(h_contor_array)\n",
    "    h_contor_array_reshaped = h_contor_array.reshape(80,-1)\n",
    "    \n",
    "    # create doc\n",
    "    for i in range(0, 80):\n",
    "        query = {\n",
    "            \"shot_number\": shot_number,\n",
    "            \"number\": i+1,\n",
    "            \"width\": 64,\n",
    "            \"height\": 64,\n",
    "            \"values\": h_contor_array_reshaped[i]\n",
    "        }\n",
    "        doc_id = 80*(shot_number-1) + i\n",
    "        ElasticManager.create_doc(index=contour_index, doc_id=doc_id, query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴点ごとのコンタ―図"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 荷重開始点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3264/3264 [09:08<00:00,  5.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "start_contour_index = \"shots-\" + target + \"-start-contour\"\n",
    "ElasticManager.delete_index(index=start_contour_index)\n",
    "ElasticManager.create_index(index=start_contour_index)\n",
    "\n",
    "# 荷重開始点\n",
    "dr = DataReader()\n",
    "start_index = \"shots-\" + target + \"-start-point\"\n",
    "start_df = dr.read_all(start_index)\n",
    "\n",
    "for shot_number in tqdm(range(1, 3265)): # 全ショットは重いので一部のショットのみ\n",
    "    if shot_number in exclude_shots:\n",
    "        continue\n",
    "        \n",
    "    shot_df = shots_df[shots_df.shot_number == shot_number].reset_index(drop=True)        \n",
    "    # print(shot_df.head(3))\n",
    "    start_in_shot_df = start_df[start_df.shot_number == shot_number].reset_index(drop=True)\n",
    "#     from IPython.core.debugger import Pdb; Pdb().set_trace()    \n",
    "    \n",
    "    h_contor_array = []\n",
    "    timestamp_by_ch = [] # ch毎のタイムスタンプ\n",
    "\n",
    "    # ch毎に1枚、計4枚のコンタ―図を作成\n",
    "    for target_ch in [\"load01\", \"load02\", \"load03\", \"load04\"]:\n",
    "        df = start_in_shot_df[start_in_shot_df.load == target_ch].reset_index(drop=True)\n",
    "        # 開始点のインデックス番号\n",
    "        start_idx = int(df.sequential_number)\n",
    "        # 開始点のインデックスにおける各chの荷重値\n",
    "        channels_df = shot_df[shot_df.sequential_number == start_idx].reset_index(drop=True)\n",
    "        load01 = float(channels_df.load01)\n",
    "        load02 = float(channels_df.load02)\n",
    "        load03 = float(channels_df.load03)\n",
    "        load04 = float(channels_df.load04)    \n",
    "\n",
    "        timestamp_by_ch.append(channels_df.timestamp.loc[0])\n",
    "        \n",
    "        z = np.zeros((64, 64), dtype=\"float64\")\n",
    "        z[20, 20] = load01\n",
    "        z[20, 40] = load02\n",
    "        z[40, 20] = load03\n",
    "        z[40, 40] = load04\n",
    "\n",
    "        _a = scipy.signal.correlate2d(z, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        h_contor_array.append(_a)\n",
    "\n",
    "    h_contor_array = np.array(h_contor_array) # (1, 64, 64)\n",
    "    h_contor_array_reshaped = h_contor_array.reshape(4,-1) # (4, 64*64=4096)\n",
    "    # from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "    \n",
    "    # create doc\n",
    "    for i, load in enumerate([\"load01\", \"load02\", \"load03\", \"load04\"]):\n",
    "        query = {\n",
    "            \"timestamp\": timestamp_by_ch[i],\n",
    "            \"shot_number\": shot_number,\n",
    "            \"load\": load,\n",
    "            \"width\": 64,\n",
    "            \"height\": 64,\n",
    "            \"values\": h_contor_array_reshaped[i]\n",
    "        }\n",
    "        doc_id = 4*(shot_number-1) + i\n",
    "        ElasticManager.create_doc(index=start_contour_index, doc_id=doc_id, query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最大荷重点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3264/3264 [09:03<00:00,  6.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "max_contour_index = \"shots-\" + target + \"-max-contour\"\n",
    "ElasticManager.delete_index(index=max_contour_index)\n",
    "ElasticManager.create_index(index=max_contour_index)\n",
    "\n",
    "dr = DataReader()\n",
    "max_index = \"shots-\" + target + \"-max-point\"\n",
    "max_df = dr.read_all(max_index)\n",
    "\n",
    "for shot_number in tqdm(range(1, 3265)): # 全ショットは重いので一部のショットのみ\n",
    "    if shot_number in exclude_shots:\n",
    "        continue\n",
    "        \n",
    "    shot_df = shots_df[shots_df.shot_number == shot_number].reset_index(drop=True)        \n",
    "    # print(shot_df.head(3))\n",
    "    max_in_shot_df = max_df[max_df.shot_number == shot_number].reset_index(drop=True)\n",
    "#     from IPython.core.debugger import Pdb; Pdb().set_trace()    \n",
    "    # ch毎に1枚、計4枚のコンタ―図を作成\n",
    "    \n",
    "    h_contor_array = []\n",
    "    timestamp_by_ch = [] # ch毎のタイムスタンプ\n",
    "    \n",
    "    for target_ch in [\"load01\", \"load02\", \"load03\", \"load04\"]:\n",
    "        df = max_in_shot_df[max_in_shot_df.load == target_ch].reset_index(drop=True)\n",
    "        # 最大点のインデックス番号\n",
    "        max_idx = int(df.sequential_number)\n",
    "        # 最大点のインデックスにおける各chの荷重値\n",
    "        channels_df = shot_df[shot_df.sequential_number == max_idx].reset_index(drop=True)\n",
    "        load01 = float(channels_df.load01)\n",
    "        load02 = float(channels_df.load02)\n",
    "        load03 = float(channels_df.load03)\n",
    "        load04 = float(channels_df.load04)    \n",
    "\n",
    "        timestamp_by_ch.append(channels_df.timestamp.loc[0])\n",
    "        \n",
    "        z = np.zeros((64, 64), dtype=\"float64\")\n",
    "        z[20, 20] = load01\n",
    "        z[20, 40] = load02\n",
    "        z[40, 20] = load03\n",
    "        z[40, 40] = load04\n",
    "\n",
    "        _a = scipy.signal.correlate2d(z, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        h_contor_array.append(_a)\n",
    "\n",
    "    h_contor_array = np.array(h_contor_array) # (1, 64, 64)\n",
    "    h_contor_array_reshaped = h_contor_array.reshape(4,-1) # (4, 64*64=4096)\n",
    "\n",
    "    for i, load in enumerate([\"load01\", \"load02\", \"load03\", \"load04\"]):\n",
    "        query = {\n",
    "            \"timestamp\": timestamp_by_ch[i],\n",
    "            \"shot_number\": shot_number,\n",
    "            \"load\": load,\n",
    "            \"width\": 64,\n",
    "            \"height\": 64,\n",
    "            \"values\": h_contor_array_reshaped[i]\n",
    "        }\n",
    "        doc_id = 4*(shot_number-1) + i\n",
    "        ElasticManager.create_doc(index=max_contour_index, doc_id=doc_id, query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 破断点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "shots-20210327141514-break-contourが存在しません。\n",
      "100%|██████████| 3264/3264 [09:01<00:00,  6.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "break_contour_index = \"shots-\" + target + \"-break-contour\"\n",
    "ElasticManager.delete_index(index=break_contour_index)\n",
    "ElasticManager.create_index(index=break_contour_index)\n",
    "\n",
    "dr = DataReader()\n",
    "break_index = \"shots-\" + target + \"-break-point\"\n",
    "break_df = dr.read_all(break_index)\n",
    "\n",
    "for shot_number in tqdm(range(1, 3265)): # 全ショットは重いので一部のショットのみ\n",
    "    if shot_number in exclude_shots:\n",
    "        continue\n",
    "        \n",
    "    shot_df = shots_df[shots_df.shot_number == shot_number].reset_index(drop=True)        \n",
    "    break_in_shot_df = break_df[break_df.shot_number == shot_number].reset_index(drop=True)\n",
    "#     from IPython.core.debugger import Pdb; Pdb().set_trace()    \n",
    "    \n",
    "    h_contor_array = []\n",
    "    timestamp_by_ch = [] # ch毎のタイムスタンプ\n",
    "    \n",
    "    # ch毎に1枚、計4枚のコンタ―図を作成\n",
    "    for target_ch in [\"load01\", \"load02\", \"load03\", \"load04\"]:\n",
    "        df = break_in_shot_df[break_in_shot_df.load == target_ch].reset_index(drop=True)\n",
    "        # 破断点のインデックス番号\n",
    "        break_idx = int(df.sequential_number)\n",
    "        # 破断点のインデックスにおける各chの荷重値\n",
    "        channels_df = shot_df[shot_df.sequential_number == break_idx].reset_index(drop=True)\n",
    "        load01 = float(channels_df.load01)\n",
    "        load02 = float(channels_df.load02)\n",
    "        load03 = float(channels_df.load03)\n",
    "        load04 = float(channels_df.load04)    \n",
    "\n",
    "        timestamp_by_ch.append(channels_df.timestamp.loc[0])\n",
    "        \n",
    "        z = np.zeros((64, 64), dtype=\"float64\")\n",
    "        z[20, 20] = load01\n",
    "        z[20, 40] = load02\n",
    "        z[40, 20] = load03\n",
    "        z[40, 40] = load04\n",
    "\n",
    "        _a = scipy.signal.correlate2d(z, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        _a = scipy.signal.correlate2d(_a, mask, mode=\"same\", boundary=\"wrap\")\n",
    "        h_contor_array.append(_a)\n",
    "\n",
    "    h_contor_array = np.array(h_contor_array) # (1, 64, 64)\n",
    "    h_contor_array_reshaped = h_contor_array.reshape(4,-1) # (4, 64*64=4096)\n",
    "    # from IPython.core.debugger import Pdb; Pdb().set_trace() \n",
    "\n",
    "    # create doc\n",
    "    for i, load in enumerate([\"load01\", \"load02\", \"load03\", \"load04\"]):\n",
    "        query = {\n",
    "            \"timestamp\": timestamp_by_ch[i],\n",
    "            \"shot_number\": shot_number,\n",
    "            \"load\": load,\n",
    "            \"width\": 64,\n",
    "            \"height\": 64,\n",
    "            \"values\": h_contor_array_reshaped[i]\n",
    "        }\n",
    "        doc_id = 4*(shot_number-1) + i\n",
    "        ElasticManager.create_doc(index=break_contour_index, doc_id=doc_id, query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下テンポラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_contor_array.shape\n",
    "h_c_ = h_contor_array.reshape(80,-1)\n",
    "h_c_[0].shape\n",
    "#print(h_c_.min(), h_c_.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 80):\n",
    "    query = {\n",
    "        \"number\": i+1,\n",
    "        \"width\": 64,\n",
    "        \"height\": 64,\n",
    "        \"values\": h_c_[i]\n",
    "    }\n",
    "    ElasticManager.create_doc(index=\"contour-001\", doc_id=i, query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElasticManager.delete_index(index=\"contour-001\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
